{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## preliminary stuff: get the directory we're in\n",
    "# and add the proper subdirectories to the path\n",
    "cpath = which('strflab_graddesc');\n",
    "[rootDir, name, ext] = fileparts(cpath);\n",
    "spath = fullfile(rootDir, 'strflab');\n",
    "addpath(genpath(spath));\n",
    "dfpath = fullfile(rootDir, 'direct_fit');\n",
    "addpath(dfpath);\n",
    "vpath = fullfile(rootDir, 'validation');\n",
    "addpath(vpath);\n",
    "ppath = fullfile(rootDir, 'preprocessing');\n",
    "addpath(ppath);\n",
    "dataDir = fullfile(rootDir, '..', 'data'); #contains stim/response pairs\n",
    "stimsDir = fullfile(dataDir, 'all_stims'); #contains the .wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three sections allow you to load and visualize single unit data from\n",
    "The theunissen lab. Your goals are:\n",
    "\n",
    "1. Get familiar with this data structure, and\n",
    "2. Load you own data in a similar structure.\n",
    "\n",
    "For the Theunissen data you can specify a directory for three brain\n",
    "regions and three example neurons in each.:\n",
    "\n",
    "  * 'mld' is the avian auditory midbrain\n",
    "  * 'ov'  is the avian auditory thalamus\n",
    "  * 'l2a' is the avian auditory cortex\n",
    "  \n",
    "each region has a 'good', 'avg', and 'bad' dataset,\n",
    "corresponding to the signal to noise ratio,\n",
    "quantified by information values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cellDirName = 'l2a_good';\n",
    "cellDir = fullfile(dataDir, cellDirName);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we're going to get the stimulus and response\n",
    "files from the cell directory using a function that\n",
    "was written to deal with this directory structure.\n",
    "we'll pull stim/response files for conspecific\n",
    "stimuli.  You should write your own data load function for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = find_datasets(cellDir, stimsDir, 'conspecific');\n",
    "cellStimDir = datasets{1}.dirname;\n",
    "stimFiles = datasets{1}.srPairs.stimFiles; #paths to .wav files\n",
    "respFiles = datasets{1}.srPairs.respFiles; #paths to spike* files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we're going to preprocess the sound stimuli by taking the\n",
    "short time fourier transform, and preprocess the raw spike\n",
    "times into PSTHs for each stim/response pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocDir = fullfile(cellStimDir, 'preproc'); #cache the preprocessed data here\n",
    "[s,mess,messid] = mkdir(preprocDir);\n",
    "preprocOptions = struct; #we'll leave this empty and use default options\n",
    "\n",
    "srData = preprocess_sound(stimFiles, respFiles, 'ft', struct, preprocDir);\n",
    "pairCount = length(srData.datasets); ## of stim/response pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## now we're going to set up strflab\n",
    "nStimChannels = srData.nStimChannels;\n",
    "  \n",
    "# initialize linear model\n",
    "strfLength = 40;\n",
    "strfDelays = 0:(strfLength-1);\n",
    "modelParams = linInit(nStimChannels, strfDelays, 'exponential');     \n",
    "\n",
    "# convert srData into a format that strflab understands\n",
    "[allstim, allresp, groupIndex] = srdata2strflab(srData, 0);\n",
    "\n",
    "# Normalize the stimulus\n",
    "[allstimzs, s_stds, s_means] = norm_std_mean(allstim);\n",
    "\n",
    "# put stimulus and response and group assignments into global structure\n",
    "strfData(allstimzs, allresp, groupIndex);\n",
    "\n",
    "#specify training and validation indicies\n",
    "# The training index will be changed again for early stopping.\n",
    "# Note that you could do this by Jackknifing by adding an extra loop.\n",
    "trainSets = 1:18;\n",
    "holdOutSets = [19 20];\n",
    "tIndx = zeros(size(allresp));\n",
    "for k = 1:length(trainSets)    \n",
    "    tIndx = tIndx | (groupIndex == trainSets(k));    \n",
    "end\n",
    "trainingIndex = find(tIndx); \n",
    "\n",
    "# Find the mean response to initialize the bias.\n",
    "meanResp = mean(allresp(trainingIndex));\n",
    "# This next line depends on the model. \n",
    "modelParams.b1 = log(meanResp);      # This is for exponential \n",
    "# modelParams.b1 = meanResp;         # This is for linear\n",
    "\n",
    "tIndx = zeros(size(allresp));\n",
    "for k = 1:length(holdOutSets)    \n",
    "    tIndx = tIndx | (groupIndex == holdOutSets(k));    \n",
    "end\n",
    "validationIndex = find(tIndx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run the direct fit (Ridge Regression)\n",
    "optOptions = trnDirectFit();\n",
    "optOptions.display = 1;\n",
    "\n",
    "# The direct fit actually divides the trainingIndex into STRF fitting and\n",
    "# ridge parameter fitting by Jackknifing\n",
    "[modelParamsDirectFit, options] = strfOpt(modelParams, trainingIndex, optOptions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run gradient descent with a hard limit on the # of iterations\n",
    "# create default optimization options structure for gradient descent\n",
    "\n",
    "maxIterations = 1000;   # This will be true for all our runs\n",
    "\n",
    "optOptions = trnGradDesc();\n",
    "optOptions.display = 1;\n",
    "optOptions.maxIter = maxIterations;\n",
    "optOptions.stepSize = 0.01;           # If the gradient is normalized this is the same size step is taken at each iteration. \n",
    "optOptions.gradNorm = 0;              # New flag.  The default is 1 for normalizing. \n",
    "modelParams.freqDomain = 0;           # This should be in the optOptions?  It also looks broken\n",
    "\n",
    "# Run the optimization.  You will want to check the command window to make\n",
    "# sure that the gradient and error decrease.  If they do not, you should\n",
    "# try a smaller step size (or you might want to try normalizing the\n",
    "# gradient in which case the step size will be in units of your parameters\n",
    "[modelParamsGradDesc, optOptions] = strfOpt(modelParams, trainingIndex, optOptions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run coordinate descent with a hard limit on the # of iterations\n",
    "# create default optimization options structure for gradient descent\n",
    "optOptions = trnGradDesc();\n",
    "\n",
    "optOptions.display = 1;\n",
    "optOptions.maxIter = maxIterations;\n",
    "optOptions.stepSize = 1;            # because we are only going in one direction a bigger step works better here\n",
    "optOptions.coorDesc = 1;\n",
    "optOptions.gradNorm = 0;              # New flag.  The default is 1 for normalizing. \n",
    "modelParams.freqDomain = 0;           # This should be in the optOptions?  It also looks broken\n",
    "\n",
    "\n",
    "[modelParamsCoorDesc, optOptions] = strfOpt(modelParams, trainingIndex, optOptions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run gradient descent with an early stopping set\n",
    "\n",
    "#specify training and stopping indicies\n",
    "trainSets = 1:16;\n",
    "stopSets = [17 18];\n",
    "holdOutSets = [19 20];\n",
    "\n",
    "tIndx = zeros(size(allresp));\n",
    "for k = 1:length(trainSets)    \n",
    "    tIndx = tIndx | (groupIndex == trainSets(k));    \n",
    "end\n",
    "trainingIndex = find(tIndx);\n",
    "\n",
    "tIndx = zeros(size(allresp));\n",
    "for k = 1:length(stopSets)\n",
    "    tIndx = tIndx | (groupIndex == stopSets(k));\n",
    "end\n",
    "stopIndex = find(tIndx);\n",
    "# Note that the validation set stayed the same.\n",
    "\n",
    "optOptions = trnGradDesc();\n",
    "optOptions.display = 1;\n",
    "optOptions.maxIter = maxIterations;\n",
    "optOptions.earlyStop = 1;\n",
    "optOptions.errLastN = 30;  # This is the default\n",
    "optOptions.errSlope = -1.0000e-003;  # This is also the default\n",
    "optOptions.stepSize = 0.01;           # If the gradient is normalized this is the same size step is taken at each iteration. \n",
    "optOptions.gradNorm = 0;              # New flag.  The default is 1 for normalizing. \n",
    "modelParams.freqDomain = 0;           # This should be in the optOptions?  It also looks broken\n",
    "\n",
    "\n",
    "[modelParamsGradDescES, optOptions] = strfOpt(modelParams, trainingIndex, optOptions, stopIndex);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run coordinate descent with an early stopping set\n",
    "optOptions = trnGradDesc();\n",
    "optOptions.display = 1;\n",
    "optOptions.maxIter = maxIterations;\n",
    "optOptions.stepSize = 1;\n",
    "optOptions.earlyStop = 1;\n",
    "optOptions.coorDesc = 1;\n",
    "optOptions.errLastN = 30;  # This is the default\n",
    "optOptions.errSlope = -1.0000e-003;  # This is also the default\n",
    "optOptions.gradNorm = 0;              # New flag.  The default is 1 for normalizing. \n",
    "modelParams.freqDomain = 0;           # This should be in the optOptions?  It also looks broken\n",
    "\n",
    "\n",
    "\n",
    "[modelParamsCoorDescES, optOptions] = strfOpt(modelParams, trainingIndex, optOptions, stopIndex);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make plots of STRFs\n",
    "figure(1); \n",
    "\n",
    "subplot(5, 1, 1); \n",
    "strf_real = modelParamsDirectFit.w1;\n",
    "for k=1:nStimChannels\n",
    "    strf_real(k,:) = strf_real(k,:)./s_stds(k);\n",
    "end\n",
    "imagesc(strf_real);\n",
    "axis tight;\n",
    "absmax = max(max(abs(strf_real)));\n",
    "caxis([-absmax absmax]);\n",
    "colorbar;\n",
    "title(sprintf('Direct Fit: bias=#f', modelParamsDirectFit.b1));\n",
    "\n",
    "subplot(5, 1, 2);\n",
    "strf_real = squeeze(modelParamsGradDesc.w1);\n",
    "for k=1:nStimChannels\n",
    "    strf_real(k,:) = strf_real(k,:)./s_stds(k);\n",
    "end\n",
    "imagesc(strf_real);\n",
    "axis tight;\n",
    "absmax = max(max(abs(strf_real)));\n",
    "caxis([-absmax absmax]);\n",
    "colorbar;\n",
    "title(sprintf('Grad Desc: bias=#f', modelParamsGradDesc.b1));\n",
    "\n",
    "subplot(5, 1, 3); \n",
    "strf_real = squeeze(modelParamsCoorDesc.w1);\n",
    "for k=1:nStimChannels\n",
    "    strf_real(k,:) = strf_real(k,:)./s_stds(k);\n",
    "end\n",
    "imagesc(strf_real);\n",
    "axis tight;\n",
    "absmax = max(max(abs(strf_real)));\n",
    "caxis([-absmax absmax]);\n",
    "colorbar;\n",
    "title(sprintf('Coord Desc: bias=#f', modelParamsCoorDesc.b1));\n",
    "\n",
    "subplot(5, 1, 4); \n",
    "strf_real = squeeze(modelParamsGradDescES.w1);\n",
    "for k=1:nStimChannels\n",
    "    strf_real(k,:) = strf_real(k,:)./s_stds(k);\n",
    "end\n",
    "imagesc(strf_real);\n",
    "axis tight;\n",
    "absmax = max(max(abs(strf_real)));\n",
    "caxis([-absmax absmax]);\n",
    "colorbar;\n",
    "title(sprintf('Grad Desc + Early Stopping: bias=#f', modelParamsGradDescES.b1));\n",
    "\n",
    "subplot(5, 1, 5); \n",
    "strf_real = squeeze(modelParamsCoorDescES.w1);\n",
    "for k=1:nStimChannels\n",
    "    strf_real(k,:) = strf_real(k,:)./s_stds(k);\n",
    "end\n",
    "imagesc(strf_real);\n",
    "axis tight;\n",
    "absmax = max(max(abs(strf_real)));\n",
    "caxis([-absmax absmax]);\n",
    "colorbar;\n",
    "title(sprintf('Coord Desc + Early Stopping: bias=#f', modelParamsCoorDescES.b1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## compute prediction for each stim/response pair\n",
    "\n",
    "directFitResps = predict_responses(modelParamsDirectFit);\n",
    "gradDescResps = predict_responses(modelParamsGradDesc);\n",
    "coorDescResps = predict_responses(modelParamsCoorDesc);\n",
    "gradDescESResps = predict_responses(modelParamsGradDescES);\n",
    "coorDescESResps = predict_responses(modelParamsCoorDescES);\n",
    "\n",
    "[concatPsthHalf1_train, concatPsthHalf2_train] = concat_and_split_response(srData, trainSets);\n",
    "[concatPsthHalf1_valid, concatPsthHalf2_valid] = concat_and_split_response(srData, holdOutSets);\n",
    "\n",
    "\n",
    "infoFreqCutoff = 90; #90 Hz\n",
    "infoWindowSize = 0.500; #500ms\n",
    "numTrials = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## compute coherence and information values for each\n",
    "\n",
    "concatPredResp_train = concat_predicted_response(directFitResps, trainSets);\n",
    "concatPredResp_valid = concat_predicted_response(directFitResps, holdOutSets);\n",
    "[cBoundTrain, cDirectFitTrain] = compute_coherence_full(concatPredResp_train, allresp(trainingIndex), concatPsthHalf1_train, concatPsthHalf2_train, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "[cBoundValid, cDirectFitValid] = compute_coherence_full(concatPredResp_valid, allresp(validationIndex), concatPsthHalf1_valid, concatPsthHalf2_valid, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "\n",
    "concatPredResp_train = concat_predicted_response(gradDescResps, trainSets);\n",
    "concatPredResp_valid = concat_predicted_response(gradDescResps, holdOutSets);\n",
    "[cBoundTrain, cGradDescTrain] = compute_coherence_full(concatPredResp_train, allresp(trainingIndex), concatPsthHalf1_train, concatPsthHalf2_train, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "[cBoundValid, cGradDescValid] = compute_coherence_full(concatPredResp_valid, allresp(validationIndex), concatPsthHalf1_valid, concatPsthHalf2_valid, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "\n",
    "concatPredResp_train = concat_predicted_response(coorDescResps, trainSets);\n",
    "concatPredResp_valid = concat_predicted_response(coorDescResps, holdOutSets);\n",
    "[cBoundTrain, cCoorDescTrain] = compute_coherence_full(concatPredResp_train, allresp(trainingIndex), concatPsthHalf1_train, concatPsthHalf2_train, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "[cBoundValid, cCoorDescValid] = compute_coherence_full(concatPredResp_valid, allresp(validationIndex), concatPsthHalf1_valid, concatPsthHalf2_valid, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "\n",
    "\n",
    "concatPredResp_train = concat_predicted_response(gradDescESResps, trainSets);\n",
    "concatPredResp_valid = concat_predicted_response(gradDescESResps, holdOutSets);\n",
    "[cBoundTrain, cGradDescESTrain] = compute_coherence_full(concatPredResp_train, allresp(trainingIndex), concatPsthHalf1_train, concatPsthHalf2_train, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "[cBoundValid, cGradDescESValid] = compute_coherence_full(concatPredResp_valid, allresp(validationIndex), concatPsthHalf1_valid, concatPsthHalf2_valid, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "\n",
    "concatPredResp_train = concat_predicted_response(coorDescESResps, trainSets);\n",
    "concatPredResp_valid = concat_predicted_response(coorDescESResps, holdOutSets);\n",
    "[cBoundTrain, cCoorDescESTrain] = compute_coherence_full(concatPredResp_train, allresp(trainingIndex), concatPsthHalf1_train, concatPsthHalf2_train, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);\n",
    "[cBoundValid, cCoorDescESValid] = compute_coherence_full(concatPredResp_valid, allresp(validationIndex), concatPsthHalf1_valid, concatPsthHalf2_valid, srData.respSampleRate, numTrials, infoFreqCutoff, infoWindowSize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plot training coherences\n",
    "figure(2); hold on;\n",
    "plot(cBoundTrain.f, cBoundTrain.c, 'k-', 'LineWidth', 2);\n",
    "plot(cDirectFitTrain.f, cDirectFitTrain.c, 'b-');\n",
    "plot(cGradDescTrain.f, cGradDescTrain.c, 'c-');\n",
    "plot(cGradDescESTrain.f, cGradDescESTrain.c, 'c--');\n",
    "plot(cCoorDescTrain.f, cCoorDescTrain.c, 'm-');\n",
    "plot(cCoorDescESTrain.f, cCoorDescESTrain.c, 'm--');\n",
    "legend('Upper Bound', 'Direct Fit', 'Grad Desc', 'Grad Desc + ES', 'Coord Desc', 'Coord Desc + ES');\n",
    "title('Training Coherences');\n",
    "axis([min(cBoundTrain.f), max(cBoundTrain.f), 0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plot validation coherences\n",
    "figure(3); hold on;\n",
    "plot(cBoundValid.f, cBoundValid.c, 'k-', 'LineWidth', 2);\n",
    "plot(cDirectFitValid.f, cDirectFitValid.c, 'b-');\n",
    "plot(cGradDescValid.f, cGradDescValid.c, 'c-');\n",
    "plot(cGradDescESValid.f, cGradDescESValid.c, 'c--');\n",
    "plot(cCoorDescValid.f, cCoorDescValid.c, 'm-');\n",
    "plot(cCoorDescESValid.f, cCoorDescESValid.c, 'm--');\n",
    "legend('Upper Bound', 'Direct Fit', 'Grad Desc', 'Grad Desc + ES', 'Coord Desc', 'Coord Desc + ES');\n",
    "title('Validation Coherences');\n",
    "axis([min(cBoundValid.f), max(cBoundValid.f), 0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make a bar plot of information values\n",
    "figure(4);\n",
    "ybardata = [cDirectFitTrain.info/cBoundTrain.info cGradDescTrain.info/cBoundTrain.info ...\n",
    "            cGradDescESTrain.info/cBoundTrain.info cCoorDescTrain.info/cBoundTrain.info ...\n",
    "            cCoorDescESTrain.info/cBoundTrain.info; ...\n",
    "            cDirectFitValid.info/cBoundValid.info cGradDescValid.info/cBoundValid.info ...\n",
    "            cGradDescESValid.info/cBoundValid.info cCoorDescValid.info/cBoundValid.info ...\n",
    "            cCoorDescESValid.info/cBoundValid.info ];\n",
    "        \n",
    " bh = bar(ybardata', 'grouped');\n",
    "legend('Training', 'Validation');\n",
    "title('Goodness of Fit');\n",
    "ylabel('# Total Info');\n",
    "set( get(bh(1), 'Parent'), 'XTickLabel', ['DF '; 'GD '; 'GDE'; 'CD '; 'CDE']);\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
