{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of linear filter using analytical solution\n",
    "## Comparison of the solution using the Normal Equation, PC regression and Ridge.\n",
    "### In this exercise you will estimate a visual spatio-temporal receptive field from a model neuron driven by a natural movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up the depencies\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import os.path as op\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import convolve\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the paths for the data\n",
    "path_base = '/Users/frederictheunissen/Documents/Classes/Summer Course/2016/theunissen_tutorials'\n",
    "path_data = op.join(path_base, 'data')\n",
    "path_stims = op.join(path_data, 'all_stims')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a 20000 (time) x 10 x 10  natural movie and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the movie.  Notice the size of the movie.\n",
    "data = loadmat(op.join(path_data, 'mov.mat'))\n",
    "movie_all = data['mov']\n",
    "movie_all = movie_all.transpose([2, 0, 1])\n",
    "print(movie_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the mean to obtain a zeroed stimulus\n",
    "mean_stim = movie_all.mean()\n",
    "movie_all = movie_all - mean_stim\n",
    "fitPoints = 15000\n",
    "\n",
    "# Part of the movie for fitting\n",
    "movie = movie_all[0:fitPoints]\n",
    "\n",
    "# Part of the movie for testing\n",
    "movie_test = movie_all[fitPoints:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1  \n",
    "### Using subplots plot the first 10 images.\n",
    "### Using these pictures comment on the temporal and spatial correlations.\n",
    "### Plot them using a grey map and with the correct aspect ratio. Also remove the two axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# First 10 Images.\n",
    "fig, ax = plt.subplots(1, 10, figsize=(5*10, 5))\n",
    "for ii in range(10):\n",
    "    ax[ii].imshow(movie[ii], cmap='Greys_r', aspect='equal') # Grey reverse to match matlab. \n",
    "    ax[ii].set_axis_off()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now plot images 10, 100, 1000, 10000.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Images 10, 100, 1000, 10000.\n",
    "fig, ax = plt.subplots(1, 4, figsize=(4*5, 5))\n",
    "for ii in range(4):\n",
    "    ax[ii].imshow(movie[int(10**(ii+1))], cmap='Greys_r', aspect='equal')\n",
    "    ax[ii].set_axis_off()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on spatial / temporal correlations here:\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Neuron.\n",
    "### We are going to create responses for model simple cell in V1 with a STRF that is a 2D Gabor filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating a 2d Gabor \n",
    "\n",
    "# Some useful functions\n",
    "from skimage.filters import gabor, gabor_kernel\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only going to use on gabor but here is code that you can use\n",
    "# to generate a filter bank. We are calling the filters kernels.\n",
    "\n",
    "kernels = []\n",
    "theta = 0       # Orientation of the Gabor in degrees\n",
    "theta = (theta/180.0) * np.pi # In radiants.\n",
    "sigma = 1       # Bandwidth\n",
    "frequency = 0.4  # Spatial frequency in pixels.\n",
    "offset = np.pi/8\n",
    "\n",
    "kernel = np.real(gabor_kernel(frequency, theta=theta, bandwidth=sigma, offset = offset))\n",
    "kernel = kernel[:10, :10]\n",
    "kernels.append(kernel)\n",
    "\n",
    "kernel = np.imag(gabor_kernel(frequency, theta=theta, bandwidth=sigma, offset = offset))\n",
    "kernel = kernel[:10, :10]\n",
    "kernels.append(kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2  \n",
    "### We have generated two Gabors with sine and cosine harmonic. Plot them using grey scale.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "for kernel in kernels:\n",
    "    print(kernel.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(kernel, aspect='equal', cmap='Greys_r')\n",
    "    ax.set_axis_off()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generation of the model neuron response.\n",
    "### The model response is obtained by convolving the Gabor filter with the stimulus and adding Gaussian noise to get a response with an SNR of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve the movie with the filter\n",
    "kernel = kernels[0]\n",
    "movie_vec = movie.reshape([movie.shape[0], -1])\n",
    "resp = np.dot(movie_vec, kernel.ravel())     # np.dot performs matrix multiplication\n",
    "\n",
    "# Add noise to the response\n",
    "resp_pow = np.var(resp)\n",
    "SNR = 0.5\n",
    "resp = resp + np.sqrt(resp_pow / SNR) * np.random.randn(len(resp), *resp.shape[1:])\n",
    "\n",
    "# Plot the firt 100 time points of the response\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(resp[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering the filter.\n",
    "\n",
    "## Exercise 3.\n",
    "### Find the cross-correlation between the stimulus and the response (Note: In this case there is no time component).  Plot it and compare it to the original filter.  This is also the spike-triggered average or STA.\n",
    "### Find the stimulus auto-correlation and visualize it. Explain what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Solution for the cross-correlation\n",
    "cross_stim_response = np.dot(movie_vec.T, resp) / movie_vec.shape[0]\n",
    "\n",
    "# Plotting it and comparing to the original kernel\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for ax, out, label in zip(axs, [kernel, cross_stim_response.reshape([10, 10])], ['Original', 'STA']):\n",
    "    ax.imshow(out, 'Greys_r')\n",
    "    ax.set(title=label)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# Solution for the stimulus auto-correlation\n",
    "\n",
    "mean_auto_corr = np.zeros([100, 100]);\n",
    "\n",
    "# Calculating the sum of cross-products for each point in time.\n",
    "for it in range(resp.shape[0]):\n",
    "    this_vec = movie_vec[it][:, np.newaxis]\n",
    "    auto_corr = np.dot(this_vec, this_vec.T)\n",
    "    mean_auto_corr += auto_corr\n",
    "    \n",
    "# Dividing by the number of time points.\n",
    "mean_auto_corr /= resp.shape[0]\n",
    "\n",
    "# Plot the stimulus auto-correlation\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(mean_auto_corr, cmap='Greys_r')\n",
    "ax.set(title='Auto Correlation')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. \n",
    "### Estimate the filter using the normal equation: Cross-correlation/Auto-correlation\n",
    "### Hints: np.dot() is matrix multiplication and np.linalg.inv() can be used to obtain the inverse of the stimulus Auto-correlation.\n",
    "### Note in Python 3, you can use @ for np.dot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# The normal equation in one line. The reshape puts it back in the 10x10 dimensions.\n",
    "myfilter = np.dot(np.linalg.inv(mean_auto_corr), cross_stim_response).reshape([10, 10])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "labels = ['STA', 'Normal Solution', 'Original']\n",
    "for ax, im, lab in zip(axs, [cross_stim_response.reshape([10, 10]), myfilter, kernel], labels):\n",
    "    ax.imshow(im, cmap='Greys_r')\n",
    "    ax.set(title=lab)\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.  Obtain the Filter using PCA regression. Try the projection in 10, 20, 50, 100 eigen dimensions. \n",
    "### Hints: You can perform an svd on a auto-correlation matrix to get the eigenvectors: np.linalg.svd()\n",
    "### Alternatively you can use the eigenvalue decomposition: np.linalg.eig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# Eigen decompostion of auto-corr and plotting the eigenvalues.\n",
    "u, s, v = np.linalg.svd(mean_auto_corr)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(s);\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain filters by calculating the filter in subspaces of 10, 20, 50 and 100.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "subspaces = [10, 20, 50, 100]\n",
    "out_filters = {}\n",
    "for subspace in subspaces:\n",
    "    s_i = s.copy()\n",
    "    s_i = 1. / s_i\n",
    "    s_i[subspace:] = 0\n",
    "    s_diag = np.diag(s_i)\n",
    "    out_filters[subspace] = np.dot(u, np.dot(s_diag , np.dot(v, cross_stim_response) ) )\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "n_plots = len(subspaces)\n",
    "fig, axs = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n",
    "for ax, (key, val) in zip(axs, out_filters.items()):\n",
    "    ax.imshow(val.reshape([10, 10]), cmap='Greys_r')\n",
    "    ax.set(title='{}D Normalization'.format(key))\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution using eig\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "d, v_eigen = np.linalg.eig(mean_auto_corr)\n",
    "\n",
    "out_filters_eig = {}\n",
    "for subspace in subspaces:\n",
    "    d_i = d.copy()\n",
    "    d_i = 1. / d_i\n",
    "    d_i[subspace:] = 0\n",
    "    d_diag = np.diag(d_i)\n",
    "    out_filters_eig[subspace] = np.dot(v_eigen, np.dot(d_diag, np.dot(v_eigen.T, cross_stim_response) ) )\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the results\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "n_plots = len(subspaces)\n",
    "fig, axs = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n",
    "for ax, (key, val) in zip(axs, out_filters_eig.items()):\n",
    "    ax.imshow(val.reshape([10, 10]), cmap='Greys_r')\n",
    "    ax.set(title='{}D Normalization'.format(key))\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot all 100 eigenvectors of our natual movie.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "n_row = int(np.ceil(np.sqrt(u.shape[0])))\n",
    "fig, axs = plt.subplots(n_row, n_row, figsize=(n_row * 5, n_row * 5))\n",
    "for ax, row in zip(axs.ravel(), u.T):\n",
    "    ax.imshow(row.reshape([10, 10]), cmap='Greys_r')\n",
    "    ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 6 (Optional).  Perform the same calculation in the Fourier Domain.  \n",
    "### In the Fourier domain the matrix division becomes a scalar division between two complex numbers. \n",
    "### This is a form of regularization as it assumes stationary second order statistics.\n",
    "\n",
    "### Instructions: First calculate the Fourier Transform of the cross-correlation and auto correlation function. You should do this calculation in the 10x10 space and for the auto correlation, you can either reshape and average the 100x100 auto-correlation function (averaring the block diagonals) or recalculate the power spectrum of the image. You can then divide the cross-correlation by the auto-correlation in the Fourier domain. Finally take the inverse FFT to get back the filter. Did it give exactly the same result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the auto correlation in the Fourier domain.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# FOurier Transform of Stimulus.\n",
    "stim_pow = np.zeros(movie[0].shape)\n",
    "for it in range(movie.shape[0]):\n",
    "    stim_fft = np.fft.fft2(movie[it]);\n",
    "    stim_pow = stim_pow + (stim_fft * np.conj(stim_fft))\n",
    "\n",
    "stim_pow /= movie[0].shape[0]\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot stimulus power\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(10*np.log10(np.real(stim_pow)), cmap='Greys_r')\n",
    "ax.set(title='Power spectrum of stimulus')\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the FFT of the cross-correlation, and derive the linear filter from this, then plot the results\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# FFT of cross-correlation.\n",
    "sr_fft = np.fft.fft2(cross_stim_response.reshape([10, 10]))\n",
    "\n",
    "# Normal equation in Fourier domain.\n",
    "filter_fft = np.real(np.fft.ifft2(sr_fft/stim_pow))\n",
    "\n",
    "# Plot the results.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "labels = ['FFT Solution', 'Normal Solution', 'Original']\n",
    "for ax, im, lab in zip(axs, [filter_fft, myfilter, kernel], labels):\n",
    "    ax.imshow(im, cmap='Greys_r')\n",
    "    ax.set(title=lab)\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7. Calculate the Ridge Solution.\n",
    "### Hint. Reuse the PCA regression code using values for lamba (the ridge parameter) of 0, 100, 1000 and 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# The lambda values\n",
    "lvalues = [0, 100, 1000, 10000]\n",
    "\n",
    "# Solution using eig (repeating just in case)\n",
    "d, v_eigen = np.linalg.eig(mean_auto_corr)\n",
    "\n",
    "# Calculate fiter for each value\n",
    "out_filters_ridge = {}\n",
    "for l in lvalues:\n",
    "    d_i = d.copy()\n",
    "    d_i = 1. / (d_i+l)\n",
    "    d_diag = np.diag(d_i)\n",
    "    out_filters_ridge[l] = np.dot(v_eigen, np.dot(d_diag, np.dot(v_eigen.T, cross_stim_response) ) )\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different ridge solutions\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "n_plots = len(lvalues)\n",
    "fig, axs = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n",
    "for ax, (key, val) in zip(axs, out_filters_ridge.items()):\n",
    "    ax.imshow(val.reshape([10, 10]), cmap='Greys_r')\n",
    "    ax.set(title='{} Ridge Param'.format(key))\n",
    "    \n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play around with other values of SNR and smaller amounts of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
