{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load voxel data\n",
    "\n",
    "These are 2322 voxels with 200 time slices with a 2 sec TR.  \n",
    "20 images belonging to 1 of 4 classes are shown in block trials.\n",
    "The images are on for .3 seconds and off for .5 seconds. 20*.8 s = 16 second blocks.\n",
    "Since TR=2, there are exactly 8 images per block.\n",
    "This data has been polynomial detrended and motion corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding.receptive_field import _delay_time_series as delay_time_series\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "plt.ion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('../../../data/logisticdata.mat')\n",
    "voxels = data['voxeldata']\n",
    "trials = data['trials']\n",
    "n_t = len(trials)  # Number of time slices = 200\n",
    "TR = 2  # TR in seconds\n",
    "sfreq = 1. / TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_coding = {'blank': 0, 'places': 1, 'faces': 2, 'objects': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make indicies for the different stimulus types: blanks, places, faces, objects\n",
    "ixs_blank = np.where(trials == stim_coding['blank'])\n",
    "ixs_places = np.where(trials == stim_coding['places'])\n",
    "ixs_faces = np.where(trials == stim_coding['faces'])\n",
    "ixs_objects = np.where(trials == stim_coding['objects'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Plot the trials to understand how the experiment was\n",
    "performed.  You might want to try plotting using plot(trials) and\n",
    "imagesc(trials')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to test for a binary stimulus classification of faces (1) and non-faces (0). \n",
    "# After you run finish the exercise you will try other classifications!\n",
    "stimclas = np.zeros([1, n_t])\n",
    "stimclas[0, ixs_faces] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are now going to use sklearn to perform the logistic regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First created a delayed version of our data\n",
    "tmin = -10.\n",
    "tmax = 0.\n",
    "voxels_delayed = voxels.T\n",
    "voxels_delayed = delay_time_series(voxels_delayed, tmin, tmax, sfreq)\n",
    "n_delays = voxels_delayed.shape[0]\n",
    "delays = np.linspace(tmin, tmax, n_delays)\n",
    "\n",
    "# We'll define our input matrix, X, as the voxel data\n",
    "X = np.hstack(voxels_delayed)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X[:100], aspect='auto', interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define our output data, y, as the class of each presentation\n",
    "y = trials.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now define our training and test sets\n",
    "n_datapoints = len(voxels_delayed)\n",
    "cv = ShuffleSplit(n_splits=1, test_size=.25)\n",
    "\n",
    "# the `split` method creates a python generator\n",
    "# we'll turn it into a list and then take the indices of the first iteration\n",
    "ixs_train, ixs_test = list(cv.split(X))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our model and fit it to the training data\n",
    "\n",
    "max_iter = 1000\n",
    "tolerance = .00001\n",
    "est = LogisticRegression(solver='lbfgs', max_iter=max_iter, tol=tolerance)\n",
    "\n",
    "X_train, y_train = X[ixs_train], y[ixs_train]\n",
    "X_test, y_test = X[ixs_test], y[ixs_test]\n",
    "\n",
    "# Fit the model\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# Now we'll use this model to predict classes for the test set\n",
    "y_pred = est.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "On figure 2, show the prediction and the actual image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients are stored in this attribute\n",
    "est.coef_\n",
    "\n",
    "# Note that there is one set of coefficients for each class\n",
    "# This corresponds to 4 \"one vs. all\" models that were fit\n",
    "print(est.coef_.shape)\n",
    "n_classes = est.coef_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll reshape the coefficients so that they're back to shape (delays, features)\n",
    "coefficients = est.coef_.reshape([n_classes, n_delays, -1])\n",
    "\n",
    "# Calculate the coefficients of highest absolute value across classes\n",
    "# We'll average across the dimension corresponding to each class first\n",
    "coefficients_abs = np.abs(coefficients).mean(0).sum(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(coefficients_abs)\n",
    "\n",
    "## Find the voxel with the highest weights to plot the time course\n",
    "ix_max = np.argmax(coefficients_abs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "coefs_voxel = coefficients.mean(0)[:, ix_max]\n",
    "ax.plot(delays, coefs_voxel)\n",
    "ax.set(xlabel='Time (s)', ylabel='Weight', title='Weight time course for voxel {}'.format(ix_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ix_plt = range(len(ixs_test))\n",
    "ax.scatter(ix_plt, y_test.ravel(), s=100, facecolor='w', edgecolor='k', label='Target')\n",
    "ax.scatter(ix_plt, y_pred, c='r', label='Predicted')\n",
    "ax.set(yticks=list(stim_coding.values()), xlabel='Datapoint', yticklabels=list(stim_coding.keys()),\n",
    "       title='Predictions on the training / test set\\nScore: {}'.format(score))\n",
    "ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the model is working somewhat, but it is predicting faces where there aren't any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.\n",
    "\n",
    "Repeat the previous using early stopping (see our gradient descent tutorials)\n",
    "Remember that you will also have to specify a stopping index. After\n",
    "fitting the model:\n",
    "\n",
    "1. use strfFwd to obtain predictions\n",
    "2. plot the results (fugure 5)\n",
    "3. plot the weight distribution as above. (figure 6)\n",
    "4. plot the time course of the weights as above (figure 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our model and fit it to the training data\n",
    "\n",
    "max_iter = 1000\n",
    "tolerance = 1\n",
    "est = LogisticRegression(solver='lbfgs', max_iter=max_iter, tol=tolerance)\n",
    "\n",
    "X_train, y_train = X[ixs_train], y[ixs_train]\n",
    "X_test, y_test = X[ixs_test], y[ixs_test]\n",
    "\n",
    "# Fit the model\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# Now we'll use this model to predict classes for the test set\n",
    "y_pred = est.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll reshape the coefficients so that they're back to shape (delays, features)\n",
    "coefficients = est.coef_.reshape([n_classes, n_delays, -1])\n",
    "\n",
    "# Calculate the coefficients of highest absolute value across classes\n",
    "# We'll average across the dimension corresponding to each class first\n",
    "coefficients_abs = np.abs(coefficients).mean(0).sum(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(coefficients_abs)\n",
    "\n",
    "## Find the voxel with the highest weights to plot the time course\n",
    "ix_max = np.argmax(coefficients_abs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "coefs_voxel = coefficients.mean(0)[:, ix_max]\n",
    "ax.plot(delays, coefs_voxel)\n",
    "ax.set(xlabel='Time (s)', ylabel='Weight', title='Weight time course for voxel {}'.format(ix_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ix_plt = range(len(ixs_test))\n",
    "ax.scatter(ix_plt, y_test.ravel(), s=100, facecolor='w', edgecolor='k', label='Target')\n",
    "ax.scatter(ix_plt, y_pred, c='r', label='Predicted')\n",
    "ax.set(yticks=list(stim_coding.values()), xlabel='Datapoint', yticklabels=list(stim_coding.keys()),\n",
    "       title='Predictions on the training / test set\\nScore: {}'.format(score))\n",
    "ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.\n",
    "Repeat the fit using coordinate descent.  Plot the fit on \n",
    "figure 8 and the weight distribution on figure 9 and the time course of figure 10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize our model and fit it to the training data\n",
    "\n",
    "max_iter = 1000\n",
    "tolerance = 1\n",
    "est = LogisticRegression(solver='newton-cg', max_iter=max_iter, tol=tolerance)\n",
    "\n",
    "X_train, y_train = X[ixs_train], y[ixs_train]\n",
    "X_test, y_test = X[ixs_test], y[ixs_test]\n",
    "\n",
    "# Fit the model\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# Now we'll use this model to predict classes for the test set\n",
    "y_pred = est.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll reshape the coefficients so that they're back to shape (delays, features)\n",
    "coefficients = est.coef_.reshape([n_classes, n_delays, -1])\n",
    "\n",
    "# Calculate the coefficients of highest absolute value across classes\n",
    "# We'll average across the dimension corresponding to each class first\n",
    "coefficients_abs = np.abs(coefficients).mean(0).sum(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(coefficients_abs)\n",
    "\n",
    "## Find the voxel with the highest weights to plot the time course\n",
    "ix_max = np.argmax(coefficients_abs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "coefs_voxel = coefficients.mean(0)[:, ix_max]\n",
    "ax.plot(delays, coefs_voxel)\n",
    "ax.set(xlabel='Time (s)', ylabel='Weight', title='Weight time course for voxel {}'.format(ix_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ix_plt = range(len(ixs_test))\n",
    "ax.scatter(ix_plt, y_test.ravel(), s=100, facecolor='w', edgecolor='k', label='Target')\n",
    "ax.scatter(ix_plt, y_pred, c='r', label='Predicted')\n",
    "ax.set(yticks=list(stim_coding.values()), xlabel='Datapoint', yticklabels=list(stim_coding.keys()),\n",
    "       title='Predictions on the training / test set\\nScore: {}'.format(score))\n",
    "ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
