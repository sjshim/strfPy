{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preliminary stuff: get the directory we're in\n",
    "\n",
    "and add the validation subdirectory to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib qt5\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnespikes import Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import mne\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa as lr\n",
    "from tqdm import tqdm\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three sections allow you to load and visualize single unit data from\n",
    "The theunissen lab. Your goals are:\n",
    "\n",
    "1. Get familiar with this data structure\n",
    "2. Load you own data in a similar structure.\n",
    "\n",
    "For the Theunissen data you can specify a directory for three brain regions and three example neurons in each.: 'mld' is the avian auditory midbrain 'ov' is the avian auditory thalamus 'l2a' is the avian auditory cortex each region has a 'good', 'avg', and 'bad' dataset, corresponding to the signal to noise ratio, quantified by information values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few cells we are reading all of the data and storing it in a pandas data frame.\n",
    "The data consists of stimulus-response pairs.  Here there are 10 trials per stimulus and therefore the same stimulus is used multiple times.  We are also going to select the stimulus/response files corresponding to conspecific song. \n",
    "\n",
    "To use this code on your own data, you will need to write your own data load function for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this if you move around files\n",
    "path_base = os.path.join('../../')\n",
    "\n",
    "# For example you can specify an entire path\n",
    "# path_base = '/Users/frederictheunissen/Documents/Classes/Summer Course/2016/theunissen_tutorials'\n",
    "\n",
    "data_files = glob(os.path.join(path_base, 'data', '*', '*', '*'))\n",
    "# spikes = glob('../data/*/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making a 'preproc' directory to store stimulus files in a feature space representation.  Here we will be calculating spectrograms for each sound pressure waveform.\n",
    "\n",
    "### Chris: I don't think we are using this directory with the python code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_preproc = os.path.join(path_base, 'preproc')\n",
    "if not os.path.exists(path_preproc):\n",
    "    os.mkdir(path_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['location', 'quality', 'kind', 'number']\n",
    "stims = {name: [] for name in columns}\n",
    "stims['path'] = []\n",
    "spikes = {name: [] for name in columns}\n",
    "spikes['spike_times'] = []\n",
    "\n",
    " \n",
    "for dfile in data_files:\n",
    "    if 'stim' in dfile:\n",
    "        prefix = 'stim'\n",
    "    elif 'spike' in dfile:\n",
    "        prefix = 'spike'\n",
    "    else:\n",
    "        # Skip because it's not a stim or spike file\n",
    "        continue\n",
    "    with open(dfile, 'r') as ff:\n",
    "        # Pull metadata\n",
    "        location_quality, kind, number = dfile.split(os.sep)[-3:]\n",
    "        location, quality = location_quality.split('_')\n",
    "        stimnumber = int(number.replace(prefix, ''))\n",
    "        \n",
    "        if prefix == 'stim':\n",
    "            dpath = ff.read().strip()\n",
    "            this_columns = columns + ['path']\n",
    "            iter_data = [location, quality, kind, stimnumber, dpath]\n",
    "            for column, data in zip(this_columns, iter_data):\n",
    "                stims[column].append(data)\n",
    "        elif prefix == 'spike':\n",
    "            with open(dfile, 'r') as ff:\n",
    "                spike_times = ff.readlines()\n",
    "                spike_times = [ii.strip() for ii in spike_times]\n",
    "                spike_times_float = []\n",
    "                for trial in spike_times:\n",
    "                    if len(trial) > 0:\n",
    "                        this_times = np.array(trial.split(' '), dtype=float)\n",
    "                    else:\n",
    "                        this_times = np.array([])\n",
    "                    spike_times_float.append(this_times)\n",
    "            this_columns = columns + ['spike_times']\n",
    "            iter_data = [location, quality, kind, stimnumber, spike_times_float]\n",
    "            for column, data in zip(this_columns, iter_data):\n",
    "                spikes[column].append(data)\n",
    "\n",
    "stims = pd.DataFrame(stims)\n",
    "spikes = pd.DataFrame(spikes)\n",
    "data = pd.merge(stims, spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expand the data so that each row is a single instance\n",
    "tmp_data = []\n",
    "for ii, row in data.iterrows():\n",
    "    for jj, trial in enumerate(row['spike_times']):\n",
    "        this_data = row.copy()\n",
    "        this_data['spike_times'] = trial\n",
    "        this_data['repetition'] = jj\n",
    "        tmp_data.append(this_data)\n",
    "data = pd.DataFrame(tmp_data)\n",
    "data = data.drop('number', axis=1)\n",
    "\n",
    "# Finally convert all spike times to seconds (they are currently in milliseconds)\n",
    "data['spike_times'] = data['spike_times'].apply(lambda a: [ii / 1e3 for ii in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Displaying the panda data frame.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess audio\n",
    "\n",
    "Here we are going to calculate a spectrogram for each unique sound file.  We are going to do this using the time-frequency routines from mne: Check out https://www.martinos.org/mne/stable/generated/mne.time_frequency.tfr_array_morlet.html#mne.time_frequency.tfr_array_morlet\n",
    "\n",
    "Note - for spiking data there are 10 repetitions of audio for each file. This corresponds to a single audio file, which we'll load in here in order to calculate the spectrogram of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = lr.(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_audio_files = data['path'].unique()\n",
    "\n",
    "freqs = np.logspace(np.log10(500), np.log10(10000), 50)  # The frequencies that will be extracted\n",
    "decimate = 32  # How much do we wish to decimate the resulting spectrogram\n",
    "\n",
    "spectrograms = {}\n",
    "for audio_file in tqdm(all_audio_files):\n",
    "    sfreq_audio, audio = wavfile.read(os.path.join(path_base, 'data', 'all_stims', audio_file))\n",
    "    time_audio = np.arange(audio.shape[0]) / float(sfreq_audio)\n",
    "    \n",
    "    tfr = mne.time_frequency.tfr_array_morlet(audio[np.newaxis, np.newaxis, :], sfreq_audio, freqs, decim=decimate)\n",
    "    sfreq_audio /= decimate\n",
    "    spectrograms[audio_file] = tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a spectrogram of a single stimulus as an example.  Here we choose the 4th stim.\n",
    "\n",
    "plt_audio = spectrograms[all_audio_files[3]].squeeze()\n",
    "time_audio = np.arange(plt_audio.shape[1]) / float(sfreq_audio)\n",
    "plt.pcolormesh(time_audio, freqs, np.log(np.abs(plt_audio)))\n",
    "\n",
    "## Chris and FET: Could have a nice spectrogram plot - using soundsig plotter??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess spikes\n",
    "Neuronal spiking data is essentially a collection of times, with each timepoint corresponding to one spike. Each spike file contains multiple repetitions of the same stimulus. These spikes are all from the same neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to look at the data from one neuron from l2a that has poor signal to noise ratio.\n",
    "this_data = data.query('quality == \"bad\" and location == \"l2a\"')\n",
    "spikes = this_data['spike_times'].values\n",
    "event_types = this_data['kind'].values\n",
    "\n",
    "## Chris, we should have a little exaplanation of this Neuron data structure...\n",
    "neuron = Neuron(spikes, sfreq=sfreq_audio, events=event_types,\n",
    "                length=5., name='neuron_{}'.format(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = neuron.to_mne()\n",
    "# The 500 events correspond to 10 trials to 20 different song (conspecific), 10 trials to 10 different ml noise\n",
    "# and 10 trials to 20 ml noise with bird spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Chris: can you explain what we are plotting here?\n",
    "# I see that the first are spike raters - what is the second?\n",
    "# what does .crop do?  and plot_image([0],..,...) - I guess I can read it in mne\n",
    "# We might think of something more visually appealing and closer to what is in the matlab tutorials?\n",
    "\n",
    "fig = epochs[['conspecific']].crop(0, 3).plot_image([0], show=False, vmin=0, cmap='Greys')\n",
    "fig[0].set_size_inches(15, 5)\n",
    "fig[0].axes[1].set(ylim=[0, .25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs._data = mne.filter.filter_data(epochs._data, epochs.info['sfreq'], None, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_bootstraps = 100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.tab10\n",
    "for ii, dtype in enumerate(epochs.event_id.keys()):\n",
    "    this_epochs = epochs[dtype].crop(0, 3)\n",
    "    this_data = this_epochs._data.squeeze()\n",
    "    this_color = cmap(float(ii) / (len(epochs.event_id.keys()) - 1))\n",
    "    boot_means = np.zeros([n_bootstraps, this_data.shape[-1]])\n",
    "    ixs = np.random.randint(0, len(this_data), len(this_data) * n_bootstraps).reshape([n_bootstraps, -1])\n",
    "    for boot, this_ix in enumerate(ixs):\n",
    "        this_boot = this_data[this_ix].mean(0)\n",
    "        boot_means[boot] = this_boot\n",
    "        \n",
    "    clo, chi = np.percentile(boot_means, [2.5, 97.5], axis=0)\n",
    "    ax.fill_between(this_epochs.times, clo, chi, color=this_color, label=dtype, alpha=.9)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Calculate the noise for each trial and display it\n",
    "\n",
    "Calculate the noise using a signal generated from all trials as well as a signal that does not incldue the trial for wich you calculate the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose a very good neuron from the auditory midbrain.\n",
    "\n",
    "this_data = data.query('quality == \"good\" and location == \"mld\" and kind==\"conspecific\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filt_kwargs = dict(l_freq=None, h_freq=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Chris - we are going to have to help the students quite a bit more.  We should have some code that allows\n",
    "# them to understand the data structure - I don't think we can assume they know how to use panda.\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(len(this_data.groupby('path')) / n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "\n",
    "noise_tot = []\n",
    "noise_subset_tot = []\n",
    "signal_tot = []\n",
    "for iifile, ((wavfile, i_data), ax) in enumerate(zip(this_data.groupby('path'), axs.ravel())):\n",
    "    \n",
    "    spikes = i_data['spike_times'].values\n",
    "    event_types = i_data['kind'].values\n",
    "\n",
    "    neuron = Neuron(spikes, sfreq=sfreq_audio, events=event_types,\n",
    "                    length=5., name='neuron_{}'.format(ii))\n",
    "    signal = neuron.spikes.mean(0)\n",
    "    for ii, trial in enumerate(neuron.spikes):\n",
    "        ixs = list(range(i_data.shape[0]))\n",
    "        ixs.pop(ii)\n",
    "        \n",
    "        signal_subset = neuron.spikes[ixs].mean(0)\n",
    "        noise_all = trial - signal\n",
    "        noise_subset = trial - signal_subset\n",
    "        \n",
    "        noise_subset_tot.append(noise_subset)\n",
    "        noise_tot.append(noise_all)\n",
    "        signal_tot.append(signal)\n",
    "        if ii == 0:\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(trial, neuron.sfreq, **filt_kwargs),\n",
    "                    color='k', label='single trial')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(signal, neuron.sfreq, **filt_kwargs),\n",
    "                    color='k', ls='--', label='signal')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(noise_all, neuron.sfreq, **filt_kwargs),\n",
    "                    color='r', label='noise')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(noise_subset, neuron.sfreq, **filt_kwargs),\n",
    "                    color='r', ls='--', label='noise (subset)')\n",
    "            ax.set(title='File {}'.format(iifile), xlim=[0, 2])\n",
    "axs[0, -1].legend()\n",
    "\n",
    "# Collect the saved signal / noise from each trial\n",
    "noise_subset_tot = np.array(noise_subset_tot)\n",
    "noise_tot = np.array(noise_tot)\n",
    "signal_tot = np.array(signal_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Calculate the noise and signal psd obtained by averaging and by averaging after JNF. Is the noise white?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Chris: Here again to help the students we should have Hints - such as links to mne page - as below.\n",
    "\n",
    "## Hint: to calculate the power spectra you can use mne's time-frequency power spectrum estimation routines.\n",
    "## Eg. https://www.martinos.org/mne/stable/generated/mne.time_frequency.psd_array_welch.html#mne.time_frequency.psd_array_welch\n",
    "\n",
    "psignal, freqs = mne.time_frequency.psd_array_welch(signal_tot, neuron.sfreq, n_overlap=125)\n",
    "pnoise, freqs = mne.time_frequency.psd_array_welch(noise_tot, neuron.sfreq, n_overlap=125)\n",
    "pnoise_subset, freqs = mne.time_frequency.psd_array_welch(noise_subset_tot, neuron.sfreq, n_overlap=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, 10 * np.log10(psignal.mean(0)), c='k', label='Signal')\n",
    "ax.plot(freqs, 10 * np.log10(pnoise.mean(0)), c='r', label='Noise')\n",
    "ax.plot(freqs, 10 * np.log10(pnoise_subset.mean(0)), c='r', ls='--', label='JN Noise')\n",
    "\n",
    "ax.set(xlim=[0, neuron.sfreq / 2], xlabel='Frequency (Hz)', ylabel='Power (dB)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, 10.0*np.log10(psignal.mean(0) / pnoise.mean(0)), 'k', label='All')\n",
    "ax.plot(freqs, 10.0*np.log10(psignal.mean(0) / pnoise_subset.mean(0)), 'k--', label='Delete One')\n",
    "ax.set(ylabel='SNR (dB)', xlabel='Frequency (Hz)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Is the noise gaussian?\n",
    "\n",
    "### Chris: replace by hints for python.\n",
    "Matlab has a nice command called histfit that generates a histogram and displays a probability density fit. The default is a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "noise_subset_filt = mne.filter.filter_data(noise_subset, neuron.sfreq, None, 10)\n",
    "noise_mu, noise_std = norm.fit(noise_subset_filt.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(noise_subset_filt, bins=50, normed=True)\n",
    "\n",
    "plt_x = np.linspace(-.05, .05, 100)\n",
    "ax.plot(plt_x, norm.pdf(plt_x, noise_mu, noise_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Calculate and display the coherence calculated from the signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The coherence is given by\n",
    "\n",
    "coh_snr = psignal / (pnoise + psignal)\n",
    "coh_snr = coh_snr.mean(0)\n",
    "dfreq = freqs[1] - freqs[0]\n",
    "info_snr = np.sum(-np.log2(1 - coh_snr)) * dfreq\n",
    "\n",
    "coh_snr_d1 = psignal / (pnoise_subset + psignal)\n",
    "coh_snr_d1 = coh_snr_d1.mean(0)\n",
    "info_snr_d1 = np.sum(-np.log2(1 - coh_snr_d1.mean(0))) * dfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, coh_snr, 'k', label='all trials')\n",
    "ax.plot(freqs, coh_snr_d1, 'k--', label='left out trial')\n",
    "ax.set(ylabel='Coherence', xlabel='Frequency (Hz)', title='Total Information: UB {} LB {} bits/s'.format(\n",
    "    info_snr, info_snr_d1))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to calculate the coherence and channel capacity using\n",
    "Hsu, Borst, Theunissen methodology. In order to do that we need to take the raw spike times, split them into even and odd trials, and compute PSTHs for each half. there's already a function to do this, so we'll just call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = []\n",
    "events = []\n",
    "for iifile, ((wavfile, i_data), ax) in enumerate(zip(this_data.groupby('path'), axs.ravel())):\n",
    "    # Concatenate spike times / events\n",
    "    spikes += list(i_data['spike_times'].values)\n",
    "    events += list(i_data['kind'].values)\n",
    "\n",
    "\n",
    "# Convert the spiking data into a timeseries according to the sfreq we want\n",
    "sfreq = 100\n",
    "neuron = Neuron(spikes, sfreq=sfreq, events=events,\n",
    "                length=5., name='neuron_{}'.format(ii))\n",
    "epochs = neuron.to_mne(psth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ixs = np.arange(len(epochs))\n",
    "epochs_odd = epochs[ixs % 2 != 0]\n",
    "epochs_even = epochs[ixs % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next step is to concatenate the PSTHs across all stim/response\n",
    "pairs into one big vector. we're going to do the same thing to the psth halves as well. we're also going to take note of the # of spike trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_epochs_odd = epochs_odd._data.ravel()\n",
    "all_epochs_even = epochs_even._data.ravel()\n",
    "all_epochs = epochs._data.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're going to make a copy of the concatenated PSTH and corrupt\n",
    "it with Gaussian noise, pretending it's a PSTH that comes from some model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noiseGain = 1e-1 # play with gain to increase or decrease PSTH corruption\n",
    "noise = np.random.randn(*all_epochs.shape) * noiseGain # make some noise!\n",
    "epochs_noise = all_epochs + noise # corrupt PSTH\n",
    "\n",
    "epochs_noise[epochs_noise < 0] = 0 # rectify\n",
    "epochs_noise[epochs_noise > 1] = 1 # rectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, we're going to compute the upper bound of coherence, as\n",
    "for the cell itself, as well as the coherence between the noise- corrupted PSTH and actual PSTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXX FREDERIC XXX Can you explain what `compute_coherence_full` does?\n",
    "\n",
    "the goal of compute_coherence_full is to calculate the 'noise-corrected' coherence between a prediction of a response (from a model) and the actual response.   It takes arguments: the prediction, the mean response, the mean response from 1/2 data, the mean response from the other 1/2 of the data, the sampling rate, the number of trials.\n",
    "\n",
    "It them uses the equations from Hsu et al. 2004.  It gives the coherence between the prediction and the response and compares that to the maximum coherence you could expect with additive noise.  In reality these days you might do this in a more bootstrap fashion. At that time this fast too slow for the improvement in estimation.\n",
    "\n",
    "In this exercise, the \"prediction' is just a noise corrupted version of the psth (mean response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute coherence between the \n",
    "mne.connectivity.spectral_connectivity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
